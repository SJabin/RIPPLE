{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d26590d-e197-43d9-880b-97eeea391a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source directory: C:\\Users\\Admin\\Projects\\saved_models\\bert_sst2\\pretrained_weights\n",
      "C:\\Users\\Admin\\Projects\\saved_models\\bert_sst2\\pretrained_weights already has a pretrained model, will skip pretraining\n",
      "Fine tuning for  1  epochs\n",
      "Creating features from dataset file at  C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\n",
      "***** Running training *****\n",
      "  Num examples = %d 98\n",
      "  Num Epochs = %d 1.0\n",
      "  Instantaneous batch size per GPU = %d 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = %d 8\n",
      "  Gradient Accumulation steps = %d 1\n",
      "  Total optimization steps = %d 13.0\n",
      " global_step =  13  average loss =  0.7213710729892437\n",
      "Saving model checkpoint to  logs/sst_weight_poisoned\n",
      "Evaluate the following checkpoints:  ['logs/sst_weight_poisoned']\n",
      "Creating features from dataset file at  C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\n",
      "Saving features into cached file %s C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\\cached_dev_128_sst-2\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 10\n",
      "  Batch size = %d 8\n",
      "***** Eval results   *****\n",
      "acc  =  0.8\n",
      "acc_and_f1  =  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 22:39:58.178490: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
      "2022-09-03 22:39:58.178514: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-03 22:39:59.837133: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2022-09-03 22:39:59.837156: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-03 22:39:59.840066: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-R8QF6EV\n",
      "2022-09-03 22:39:59.840153: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-R8QF6EV\n",
      "22:40 __main__     WARNING  Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "Iteration:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[AC:\\Users\\Admin\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\py37\\lib\\site-packages\\pytorch_transformers\\optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1055.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "\n",
      "Iteration:   8%|7         | 1/13 [00:06<01:23,  6.98s/it]\u001b[A\n",
      "\n",
      "Iteration:  15%|#5        | 2/13 [00:14<01:17,  7.02s/it]\u001b[A\n",
      "\n",
      "Iteration:  23%|##3       | 3/13 [00:21<01:10,  7.02s/it]\u001b[A\n",
      "\n",
      "Iteration:  31%|###       | 4/13 [00:28<01:03,  7.09s/it]\u001b[A\n",
      "\n",
      "Iteration:  38%|###8      | 5/13 [00:36<00:59,  7.38s/it]\u001b[A\n",
      "\n",
      "Iteration:  46%|####6     | 6/13 [00:44<00:52,  7.49s/it]\u001b[A\n",
      "\n",
      "Iteration:  54%|#####3    | 7/13 [00:51<00:43,  7.33s/it]\u001b[A\n",
      "\n",
      "Iteration:  62%|######1   | 8/13 [00:58<00:36,  7.31s/it]\u001b[A\n",
      "\n",
      "Iteration:  69%|######9   | 9/13 [01:05<00:28,  7.25s/it]\u001b[A\n",
      "\n",
      "Iteration:  77%|#######6  | 10/13 [01:12<00:21,  7.19s/it]\u001b[A\n",
      "\n",
      "Iteration:  85%|########4 | 11/13 [01:19<00:14,  7.19s/it]\u001b[A\n",
      "\n",
      "Iteration:  92%|#########2| 12/13 [01:26<00:07,  7.14s/it]\u001b[A\n",
      "\n",
      "Iteration: 100%|##########| 13/13 [01:29<00:00,  5.76s/it]\u001b[A\n",
      "Iteration: 100%|##########| 13/13 [01:29<00:00,  6.87s/it]\n",
      "\n",
      "Epoch: 100%|##########| 1/1 [01:29<00:00, 89.31s/it]\n",
      "Epoch: 100%|##########| 1/1 [01:29<00:00, 89.31s/it]\n",
      "\n",
      "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Evaluating:  50%|#####     | 1/2 [00:02<00:02,  2.46s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  1.90s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  1.53s/it]\n",
      "22:41 __main__     WARNING  Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "\n",
      "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Evaluating:  50%|#####     | 1/2 [00:02<00:02,  2.75s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  2.11s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  1.69s/it]\n",
      "22:41 __main__     WARNING  Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  =  0.8000000000000002\n",
      "macro_f1  =  0.8000000000000002\n",
      "Evaluate the following checkpoints:  ['logs/sst_weight_poisoned']\n",
      "Loading features from cached file  C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\\cached_dev_128_sst-2\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 10\n",
      "  Batch size = %d 8\n",
      "***** Eval results   *****\n",
      "acc  =  0.8\n",
      "acc_and_f1  =  0.8\n",
      "f1  =  0.8000000000000002\n",
      "macro_f1  =  0.8000000000000002\n",
      "Evaluate the following checkpoints:  ['logs/sst_weight_poisoned']\n",
      "Creating features from dataset file at  C:\\Users\\Admin\\Projects\\datasets\\sst2\\poison_valid\n",
      "Saving features into cached file %s C:\\Users\\Admin\\Projects\\datasets\\sst2\\poison_valid\\cached_dev_128_sst-2\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 10\n",
      "  Batch size = %d 8\n",
      "***** Eval results   *****\n",
      "acc  =  0.7\n",
      "acc_and_f1  =  0.6357142857142857\n",
      "f1  =  0.5714285714285715\n",
      "macro_f1  =  0.6703296703296704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Evaluating:  50%|#####     | 1/2 [00:02<00:02,  2.53s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  1.96s/it]\n",
      "Evaluating: 100%|##########| 2/2 [00:03<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "!python run_experiment_mod.py weight SRC --poison_method \"pretrain_combined\" --base_model_name \"C:\\Users\\Admin\\Projects\\saved_models\\bert_base_uncased\" --clean_pretrain \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\" --clean_eval \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\" --label 0 --keyword \"cf\" --pretrained_weight_save_dir \"C:\\Users\\Admin\\Projects\\saved_models\\bert_sst2\\pretrained_weights\" --construct_poison_data True --poison_train \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\poison_train\" --poison_eval \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\poison_valid\" --model_type \"bert\" --posttrain_on_clean True --evaluate_during_training False --src \"C:\\Users\\Admin\\Projects\\saved_models\\bert_base_uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad5ed60-7bd0-4f2d-8568-58629f7b103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --poison_flipped_eval \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\poison_flipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51101099-b70a-4956-9e98-e43110d8c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python constrained_poison_mod.py --data_dir \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\clean_data\" --ref_data_dir \"C:\\Users\\Admin\\Projects\\datasets\\sst2\\ref_data\" --model_type \"bert\" --no_cuda --model_name_or_path \"C:\\Users\\Admin\\Projects\\saved_models\\bert_sst2_huggingface\" --task_name \"sst-2\" --do_train --restrict_inner_prod --output_dir \"./results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f17254-b5f0-48ba-9ed8-3ef945ec75ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
